{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eaf43f0a044b4f23b2659ab06f26eb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_19d2b95bece2494b9b7fa14aca8575b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c1a62492175b4d0bb993ab69e312745a",
              "IPY_MODEL_a190e861c5a64e378ac2391c80983f9d"
            ]
          }
        },
        "19d2b95bece2494b9b7fa14aca8575b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1a62492175b4d0bb993ab69e312745a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_29cdd88505c74b2a9406a651f6c327a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f05cb9d433d94299b698267bd7f1728a"
          }
        },
        "a190e861c5a64e378ac2391c80983f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_969dfb9d3f014705986ad354a5f5b017",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 31948551.61it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50f2aed241b845af8b9caee4d6954232"
          }
        },
        "29cdd88505c74b2a9406a651f6c327a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f05cb9d433d94299b698267bd7f1728a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "969dfb9d3f014705986ad354a5f5b017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50f2aed241b845af8b9caee4d6954232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsdoxTY_QzFE",
        "colab_type": "code",
        "outputId": "16a08553-5565-42b4-e52a-616b2d04d90f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun  8 14:09:16 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIhFcIL-XOMx",
        "colab_type": "code",
        "outputId": "d5d0039b-2dc3-489e-b358-5913bcfd0e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kWwNAH-XONB",
        "colab_type": "text"
      },
      "source": [
        "Dataset: CIFAR 10, resize image to 224x224"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwmTPzSXXONF",
        "colab_type": "code",
        "outputId": "1ba1e557-cfca-4249-9f0e-0e6c996fbcd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "eaf43f0a044b4f23b2659ab06f26eb76",
            "19d2b95bece2494b9b7fa14aca8575b9",
            "c1a62492175b4d0bb993ab69e312745a",
            "a190e861c5a64e378ac2391c80983f9d",
            "29cdd88505c74b2a9406a651f6c327a1",
            "f05cb9d433d94299b698267bd7f1728a",
            "969dfb9d3f014705986ad354a5f5b017",
            "50f2aed241b845af8b9caee4d6954232"
          ]
        }
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize((224,224)), # Resize tensor từ 32x32 thành 224x224 để phù hợp với đầu vào của AlexNet\n",
        "                                transforms.ToTensor() # chuyển ảnh đang ở dạng PIL image thành tensor\n",
        "                                ]) \n",
        "cifar = torchvision.datasets.CIFAR10(root=\"../data/\", train=True, \n",
        "                                     transform=transform, \n",
        "                                     target_transform=None, \n",
        "                                     download=True)\n",
        "batch_size = 128\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=cifar,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaf43f0a044b4f23b2659ab06f26eb76",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqkVZzcqXONQ",
        "colab_type": "text"
      },
      "source": [
        "Hãy xem thử dữ liệu có dạng như thế nào?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o5NzAAeXONR",
        "colab_type": "code",
        "outputId": "3c9019c6-70f2-4eae-8773-226b37af2a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_iter = iter(train_loader)\n",
        "x, y = train_iter.next()\n",
        "print(x.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdmMbNNQXONZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md-bqPdkXONe",
        "colab_type": "text"
      },
      "source": [
        "Define the Network architechture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRdF4Z9KXONt",
        "colab_type": "text"
      },
      "source": [
        "<figure>\n",
        "    <img src=\"https://github.com/cuongvng/neural-networks-with-PyTorch/blob/master/CNNs/AlexNet/img/AlexNetArchitecture.png?raw=1\" width=\"25%\" class=\"center\"/>\n",
        "    <figcaption>Cấu trúc mạng AlexNet</figcaption>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEf3Jz3WXONz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__() # Gọi hàm __init__() của `nn.Module`\n",
        "        \n",
        "        # Sau đó định nghĩa các tầng Conv2d trong mạng tại đây luôn.\n",
        "        # Khối MaxPool không cần định nghĩa, ta thực hiện phép toán đó tại phương thức `forward`.\n",
        "        \n",
        "        # Tầng đầu tiên trên hình, 11x11 Conv2d \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4)\n",
        "        # Tương tự với các tầng Conv2d tiếp theo, số kênh đầu ra của tầng trước là số kênh đầu vào\n",
        "        # của tầng hiện tại:\n",
        "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1)\n",
        "        \n",
        "        # Đến 3 tầng kết nối đầy đủ (Fully-connected Layer, hay Dense). \n",
        "        # Xác định đối số `in_features` cho tầng thứ nhất bằng tích số kênh tầng Conv2d cuối (conv5) \n",
        "        # với kích thước ảnh sau tầng đó.\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features=384*2*2, out_features=4096) # Chỗ này có cách lấy `in_features` mà ko cần tính toán nhức đầu\n",
        "        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n",
        "        \n",
        "        # Tầng FC cuối cùng, đối số out_features ở đây bằng số lượng nhãn trong MNIST dataset, là 10, \n",
        "        # không phải 1000 như hình trên (hình trong paper gốc).\n",
        "        self.fc3 = nn.Linear(in_features=4096, out_features=10)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Hàm này định nghĩa cách ảnh đầu vào X (dạng tensor) được truyền qua từng tầng của mạng.\n",
        "        X = X.type(torch.float) # chuyển kiểu từ int sang float\n",
        "\n",
        "        X = F.relu(self.conv1(X))\n",
        "        X = torch.max_pool2d(X, kernel_size=3, stride=2)\n",
        "        X = F.relu(self.conv2(X))\n",
        "        X = torch.max_pool2d(X, kernel_size=3, stride=2)\n",
        "        X = F.relu(self.conv3(X))\n",
        "        X = F.relu(self.conv4(X))\n",
        "        X = F.relu(self.conv5(X))\n",
        "        X = F.max_pool2d(X, kernel_size=3, stride=2)\n",
        "#         print(X.size()) # In dòng này để tính shape cho tầng fc1.\n",
        "        \n",
        "        X = torch.flatten(X, start_dim=1) # Làm phẳng tensor 4D thành tensor 2D để đưa vào tầng FC.\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = F.relu(self.fc2(X))\n",
        "        # Sử dụng hàm kích hoạt `softmax` ở tầng cuối cùng để tính xác suất 10 nhãn đầu ra.\n",
        "        X = F.softmax(self.fc3(X))\n",
        "        return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvVvDM1tXON6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X = torch.randn((1,3,224,224))\n",
        "# y=AlexNet()(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb2l6xEqXOOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0d9f2191-47c0-45d4-9a6f-7948a2f0db03"
      },
      "source": [
        "net = AlexNet()\n",
        "net.to(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
              "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(2, 2))\n",
              "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=1536, out_features=4096, bias=True)\n",
              "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (fc3): Linear(in_features=4096, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXzjzoM5XOOK",
        "colab_type": "code",
        "outputId": "fc2610f0-8af4-4869-f88f-25f9e1a12a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Thử in ra kích thước các tham số của mạng\n",
        "for i, p in enumerate(net.parameters()):\n",
        "    print(i, p.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([96, 3, 11, 11])\n",
            "1 torch.Size([96])\n",
            "2 torch.Size([256, 96, 5, 5])\n",
            "3 torch.Size([256])\n",
            "4 torch.Size([384, 256, 3, 3])\n",
            "5 torch.Size([384])\n",
            "6 torch.Size([384, 384, 3, 3])\n",
            "7 torch.Size([384])\n",
            "8 torch.Size([384, 384, 3, 3])\n",
            "9 torch.Size([384])\n",
            "10 torch.Size([4096, 1536])\n",
            "11 torch.Size([4096])\n",
            "12 torch.Size([4096, 4096])\n",
            "13 torch.Size([4096])\n",
            "14 torch.Size([10, 4096])\n",
            "15 torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kceNclJxXOON",
        "colab_type": "text"
      },
      "source": [
        "Define the loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "980Ncse2XOOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(),lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCetiBaMXOOU",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIigXX_3XOOb",
        "colab_type": "code",
        "outputId": "a6a34bbb-c1e6-4644-9078-4867da343733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "n_epochs = 10\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i, data in enumerate(train_loader): # Với mỗi batch:\n",
        "        X, y = data # data là 1 tuple (X, y), dòng này unpack tuple đó để gán vào X, y.\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad() # Reset các gradient trọng số sau mỗi lần cập nhật trọng số ở mỗi batch, nếu không chúng sẽ tích luỹ, gây ảnh hưởng đến các batch sau.\n",
        "        \n",
        "        predictions = net(X) # Thực hiện lượt truyền xuôi (forward pass) cho batch hiện tại -> có kết quả nhãn dự đoán \n",
        "        loss = criterion(predictions, y) # Tính hàm mất mát dựa vào dự đoán và nhãn gốc\n",
        "        loss.backward() # Thực hiện lan truyền ngược (backward pass)\n",
        "        \n",
        "        optimizer.step() # Cập nhật các tham số của mô hình\n",
        "\n",
        "print(\"Done!\")\n",
        "        "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmVt4-JpXOOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}